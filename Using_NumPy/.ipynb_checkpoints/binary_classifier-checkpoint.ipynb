{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a64db3b2-f832-4f17-8df6-2143bc32d5dc",
   "metadata": {},
   "source": [
    "# NumPy Binary Classifier\n",
    "\n",
    "In this notebook, I would like to show you what is the main logic behind the common deep learning frameworks. I found this interesting since I usually tweet the hyperparameters framework's functions without really knowing what is changing into the equations.\n",
    "\n",
    "So, a matrix point of view gives a better overview of *how a Neural Network works*, and once you're familiar with those notions, you will be able to construct deeper and more complex N.N. with the help of deep learning frameworks, knowing what you are doing. Also, it will help you to tune your model, once it has been trained, to improve it.\n",
    "\n",
    "The goal of this classifier is to detect whether an image is a Pikachu or a Jigglypuff (english version of Rondoudou)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da41b93-c61a-4104-8616-3da572eb0ee9",
   "metadata": {},
   "source": [
    "## Data\n",
    "First we need to work on the dataset to feed the neural network with the right dimensions, types etc. For the purpuse of the exercice, I didn't chose a large dataset, it contains :\n",
    "- 98 Pikachu images (label 0)\n",
    "- 76 Jigglypuff [Rondoudou] images (label 1)\n",
    "\n",
    "So 174 images that we have to randomize and split into train and test sets. \n",
    "\n",
    "### Data loading\n",
    "We are going to create a function which returns train/val sets and their correspondant labels. This function should let us decide what size the validation set will be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8beb104-9992-484c-be1a-01a3b24551aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import math\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3da9f4ea-64f8-4eda-9f3d-72f7710448e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_data(val_size=0.2):\n",
    "    \"\"\"\n",
    "    Converts images to arrays and returns them randomized through training and \n",
    "    validation set.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    val_size : float, optional\n",
    "        Part of validation set. The default is 0.2.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data_train : np.array of shape (nb_img, HEIGHT, WIDTH, nb_chans)\n",
    "        Training set.\n",
    "    label_train : np.array of shape (nb_img, 1)\n",
    "        Labels of the training set.\n",
    "    data_val : np.array of shape (nb_img, HEIGHT, WIDTH, nb_chans)\n",
    "        Validation set.\n",
    "    label_val : np.array of shape (m, 1)\n",
    "        Labels of the validation set.\n",
    "    classes : np.array of shape (2,)\n",
    "        Classe names : Pikachu / Rondoudou. They are encode in bytes.\n",
    "\n",
    "    \"\"\"\n",
    "    list_pikachu = glob.glob('../data/pikachu/*')\n",
    "    list_rondoudou = glob.glob('../data/rondoudou/*')\n",
    "    \n",
    "    HEIGHT = 100\n",
    "    WIDTH = 100\n",
    "    CHANNEL = 3\n",
    "    \n",
    "    classes = np.array([b'Pikachu', b'Rondoudou'])\n",
    "    \n",
    "    # Initialisations\n",
    "    size_dataset = len(list_pikachu) + len(list_rondoudou)\n",
    "    dataset_arr = np.zeros((size_dataset, HEIGHT, WIDTH, CHANNEL))\n",
    "    label = np.zeros((size_dataset, 1), dtype='int')\n",
    "    \n",
    "    # Generating a Pikachu array-type dataset\n",
    "    for k in range(len(list_pikachu)):\n",
    "        with Image.open(list_pikachu[k]) as im :\n",
    "            im = im.resize((HEIGHT, WIDTH), resample=Image.BICUBIC)\n",
    "            im = im.convert(\"RGB\")\n",
    "        img_arr = np.array(im)\n",
    "        dataset_arr[k] = img_arr\n",
    "        \n",
    "    # Generating a Rondoudou array type dataset\n",
    "    i=0\n",
    "    for k in range(len(list_pikachu), len(dataset_arr)):\n",
    "        with Image.open(list_rondoudou[i]) as im2 :\n",
    "            im2 = im2.resize((HEIGHT, WIDTH), resample=Image.BICUBIC)\n",
    "            im2 = im2.convert(\"RGB\")\n",
    "        img_arr = np.array(im2)\n",
    "        dataset_arr[k] = img_arr\n",
    "        label[k] = 1\n",
    "        i+=1\n",
    "    \n",
    "    # Randomizing\n",
    "    n_samples = dataset_arr.shape[0]\n",
    "    n_val = int(val_size * n_samples)\n",
    "    shuffled_indices = np.random.permutation(n_samples)\n",
    "    train_indices = shuffled_indices[:-n_val] \n",
    "    val_indices = shuffled_indices[-n_val:]\n",
    "\n",
    "    data_train = dataset_arr[train_indices]\n",
    "    label_train = label[train_indices]\n",
    "    \n",
    "    data_val = dataset_arr[val_indices]\n",
    "    label_val = label[val_indices]\n",
    "    \n",
    "    return data_train, label_train, data_val, label_val, classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155d5d12-d641-49e2-9994-ee7872d1bb7c",
   "metadata": {},
   "source": [
    "### Import data : handling mini-batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cbde7f-06cc-4dfc-a694-aef6295db09a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
