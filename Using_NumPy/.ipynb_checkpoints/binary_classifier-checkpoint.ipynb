{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9280e740-0300-44fe-8ca9-09c4b4f7c7c7",
   "metadata": {},
   "source": [
    "### Table of content\n",
    "* [Data](#chapter1)\n",
    "    * [Data loading](#section_1_1)\n",
    "    * [Handling mini-batches](#section_1_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64db3b2-f832-4f17-8df6-2143bc32d5dc",
   "metadata": {},
   "source": [
    "# NumPy Binary Classifier \n",
    "\n",
    "In this notebook, I would like to show you what is the main logic behind the common deep learning frameworks. I found this interesting since I usually tweet the hyperparameters framework's functions without really knowing what is changing into the equations.\n",
    "\n",
    "So, a matrix point of view gives a better overview of *how a Neural Network works*, and once you're familiar with those notions, you will be able to construct deeper and more complex N.N. with the help of deep learning frameworks, knowing what you are doing. Also, it will help you to tune your model, once it has been trained, to improve it.\n",
    "\n",
    "The goal of this classifier is to detect whether an image is a Pikachu or a Jigglypuff (english version of Rondoudou)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da41b93-c61a-4104-8616-3da572eb0ee9",
   "metadata": {},
   "source": [
    "## Data <a class=\"anchor\" id=\"chapter1\"></a>\n",
    "First we need to work on the dataset to feed the neural network with the right dimensions, types etc. For the purpuse of the exercice, I didn't chose a large dataset, it contains :\n",
    "- 98 Pikachu images (label 0)\n",
    "- 76 Jigglypuff [Rondoudou] images (label 1)\n",
    "\n",
    "So 174 images that we have to randomize and split into train and test sets. \n",
    "\n",
    "### Data loading <a class=\"anchor\" id=\"section_1_1\"></a>\n",
    "We are going to create a function which returns train/val sets and their correspondant labels. This function should let us decide the size of the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8beb104-9992-484c-be1a-01a3b24551aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import math\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3da9f4ea-64f8-4eda-9f3d-72f7710448e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_data(val_size=0.2):\n",
    "    \"\"\"\n",
    "    Converts images to arrays and returns them randomized through training and \n",
    "    validation set.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    val_size : float, optional\n",
    "        Part of validation set. The default is 0.2.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data_train : np.array of shape (nb_img, HEIGHT, WIDTH, nb_chans)\n",
    "        Training set.\n",
    "    label_train : np.array of shape (nb_img, 1)\n",
    "        Labels of the training set.\n",
    "    data_val : np.array of shape (nb_img, HEIGHT, WIDTH, nb_chans)\n",
    "        Validation set.\n",
    "    label_val : np.array of shape (m, 1)\n",
    "        Labels of the validation set.\n",
    "    classes : np.array of shape (2,)\n",
    "        Classe names : Pikachu / Rondoudou. They are encode in bytes.\n",
    "\n",
    "    \"\"\"\n",
    "    list_pikachu = glob.glob('../data/pikachu/*')\n",
    "    list_rondoudou = glob.glob('../data/rondoudou/*')\n",
    "    \n",
    "    HEIGHT = 100\n",
    "    WIDTH = 100\n",
    "    CHANNEL = 3\n",
    "    \n",
    "    classes = np.array([b'Pikachu', b'Rondoudou'])\n",
    "    \n",
    "    # Initialisations\n",
    "    size_dataset = len(list_pikachu) + len(list_rondoudou)\n",
    "    dataset_arr = np.zeros((size_dataset, HEIGHT, WIDTH, CHANNEL))\n",
    "    label = np.zeros((size_dataset, 1), dtype='int')\n",
    "    \n",
    "    # Generating a Pikachu array-type dataset\n",
    "    for k in range(len(list_pikachu)):\n",
    "        with Image.open(list_pikachu[k]) as im :\n",
    "            im = im.resize((HEIGHT, WIDTH), resample=Image.BICUBIC)\n",
    "            im = im.convert(\"RGB\")\n",
    "        img_arr = np.array(im)\n",
    "        dataset_arr[k] = img_arr\n",
    "        \n",
    "    # Generating a Rondoudou array type dataset\n",
    "    i=0\n",
    "    for k in range(len(list_pikachu), len(dataset_arr)):\n",
    "        with Image.open(list_rondoudou[i]) as im2 :\n",
    "            im2 = im2.resize((HEIGHT, WIDTH), resample=Image.BICUBIC)\n",
    "            im2 = im2.convert(\"RGB\")\n",
    "        img_arr = np.array(im2)\n",
    "        dataset_arr[k] = img_arr\n",
    "        label[k] = 1\n",
    "        i+=1\n",
    "    \n",
    "    # Randomizing\n",
    "    n_samples = dataset_arr.shape[0]\n",
    "    n_val = int(val_size * n_samples)\n",
    "    shuffled_indices = np.random.permutation(n_samples)\n",
    "    train_indices = shuffled_indices[:-n_val] \n",
    "    val_indices = shuffled_indices[-n_val:]\n",
    "\n",
    "    data_train = dataset_arr[train_indices]\n",
    "    label_train = label[train_indices]\n",
    "    \n",
    "    data_val = dataset_arr[val_indices]\n",
    "    label_val = label[val_indices]\n",
    "    \n",
    "    return data_train, label_train, data_val, label_val, classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155d5d12-d641-49e2-9994-ee7872d1bb7c",
   "metadata": {},
   "source": [
    "### Handling mini-batches <a class=\"anchor\" id=\"section_1_2\"></a>\n",
    "Using mini-batches is an optimization method which permits to let gradient descent makes progress *before* finishing of precessing the *entire* training set. So, we need to create a function capable of splitting a training dataset into mini-batches of size `mini_batch_size` with the corresponding labels for each image in each mini-batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88cbde7f-06cc-4dfc-a694-aef6295db09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n",
    "    \"\"\"\n",
    "    Creates a list of random minibatches from (X, Y)\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input data, of shape (input size, number of examples)\n",
    "    Y -- true \"label\" vector (1 for blue dot / 0 for red dot), of shape (1, number of examples)\n",
    "    mini_batch_size -- size of the mini-batches, integer\n",
    "    \n",
    "    Returns:\n",
    "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(seed)            # To make your \"random\" minibatches the same as ours\n",
    "    m = X.shape[1]                  # number of training examples\n",
    "    mini_batches = []\n",
    "        \n",
    "    # Step 1: Shuffle (X, Y)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[:, permutation]\n",
    "    shuffled_Y = Y[:, permutation].reshape((1, m))\n",
    "    \n",
    "    inc = mini_batch_size\n",
    "\n",
    "    # Step 2 - Partition (shuffled_X, shuffled_Y).\n",
    "    # Cases with a complete mini batch size only i.e each of 64 examples.\n",
    "    num_complete_minibatches = math.floor(m / mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        mini_batch_X = shuffled_X[:, k * inc : (k+1) * inc]\n",
    "        mini_batch_Y = shuffled_Y[:, k * inc : (k+1) * inc]\n",
    "    \n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # For handling the end case (last mini-batch < mini_batch_size i.e less than 64)\n",
    "    if m % mini_batch_size != 0:\n",
    "        mini_batch_X = shuffled_X[:, (k+1) * inc : ]\n",
    "        mini_batch_Y = shuffled_Y[:, (k+1) * inc : ]\n",
    "        \n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d7e6d2-3b97-4d27-94b0-1c29393bf804",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
